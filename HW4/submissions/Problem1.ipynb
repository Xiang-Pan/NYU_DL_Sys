{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem we will train a convolutional neural network for image classification using transfer learning. Transfer learning involves training a base network from scratch on a very large dataset (e.g., Imagenet1K with 1.2 M images and 1K categories) and then using this base network either as a feature extractor or as an initialization network for target task. Thus two major transfer learning scenarios are as follows:\n",
    "\n",
    "- Finetuning the base model: Instead of random initialization, we initialize the network with a pretrained network, like the one that is trained on Imagenet dataset. Rest of the training looks as usual however the learning rate schedule for transfer learning may be different.\n",
    "\n",
    "- Base model as fixed feature extractor: Here, we will freeze the weights for all of the network except that of the final fully connected layer. This last fully connected layer is replaced with a new one with random weights and only this layer is trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use **CIFAR100** as our dastaset. \n",
    "\n",
    "We use the introduction from official website:\n",
    "\n",
    "This dataset is just like the CIFAR-10, except it has 100 classes containing 600 images each. There are 500 training images and 100 testing images per class. The 100 classes in the CIFAR-100 are grouped into 20 superclasses. Each image comes with a \"fine\" label (the class to which it belongs) and a \"coarse\" label (the superclass to which it belongs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torchvision.models import resnet50\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# prepare_dataset\n",
    "train_transform = transforms.Compose([transforms.ToTensor()])\n",
    "test_transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = CIFAR100(root='./cached_datasets', train=True, transform=train_transform, download=True)\n",
    "test_dataset = CIFAR100(root='./cached_datasets', train=False, transform=test_transform, download=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description\n",
    "\n",
    "CIFAR100 is "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the class 0 and class 1 to display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = CIFAR100(root='./cached_datasets', train=True, transform=None, download=True)\n",
    "\n",
    "def select_class(class_num=0):\n",
    "    for i in range(len(train_dataset)):\n",
    "        if train_dataset.targets[i] == class_num:\n",
    "            yield train_dataset.data[i]\n",
    "\n",
    "# display PIL Image\n",
    "import matplotlib.pyplot as plt\n",
    "g0 = select_class(class_num=0)\n",
    "g1 = select_class(class_num=1)\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(2):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.imshow(next(g0))\n",
    "    plt.axis('off')\n",
    "\n",
    "for i in range(2):\n",
    "    plt.subplot(2,2,i+3)\n",
    "    plt.imshow(next(g1))\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We display the class 0 and clas 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target feature is various features of the objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)\n",
    "First finetune by setting the same value of hyperparameters (learning rate=0.001, momentum=0.9) for all the layers. Keep batch size of 64 and train for 200-300 epochs or until model converges well. You will use a multi-step learning rate schedule and decay by a factor of 0.1 ( γ = 0.1 in the link below). You can choose steps at which you want to decay the learning rate but do 3 drops during the training. So the first drop will bring down the learning rate to 0.0001, second to 0.00001, third to 0.000001. For example, if training for 200 epochs, first drop can happen at epoch 60, second at epoch 120 and third at epoch 180. (8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "class ResNetLightningModule(pl.LightningModule):\n",
    "    def __init__(self, hidden_size, output_size, optimizer_name='adam', use_dropout=False):\n",
    "        super(ResNetLightningModule, self).__init__()\n",
    "        self.model = resnet50(pretrained=True, progress=True)\n",
    "        self.model.fc = nn.Linear(2048, 100)\n",
    "\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.acc_metric = torchmetrics.Accuracy()\n",
    "        self.optimizer_name = optimizer_name\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        acc = self.acc_metric(y_hat, y)\n",
    "        self.log('train_loss', loss, prog_bar=False, on_epoch=True)\n",
    "        self.log('train_acc', acc, prog_bar=False, on_epoch=True)\n",
    "        logs = {'train_loss': loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        acc = self.acc_metric(y_hat, y)\n",
    "        self.log('val_loss', loss, prog_bar=False, on_epoch=True)\n",
    "        self.log('val_acc', acc, prog_bar=False, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        lr = 0.001\n",
    "        momentum = 0.9\n",
    "        batch_size = 64\n",
    "        optimizer = torch.optim.SGD(self.model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "        # multi_step_lr_scheduler\n",
    "        # For example, if training for 200 epochs, first drop can happen at epoch 60, second at epoch 120 and third at epoch 180.\n",
    "        scheduler = MultiStepLR(optimizer, milestones=[60, 120, 180], gamma=0.1)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Results\n",
    "\n",
    "All Layer Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "api = wandb.Api()\n",
    "\n",
    "# Project is specified by <entity/project-name>\n",
    "runs = api.runs(\"xiang-pan/NYU_DL_Sys-HW4_problem1\")\n",
    "summary_list = [] \n",
    "config_list = [] \n",
    "name_list = [] \n",
    "for run in runs: \n",
    "    # run.summary are the output key/values like accuracy.\n",
    "    # We call ._json_dict to omit large files \n",
    "    summary_list.append(run.summary._json_dict) \n",
    "    # print(run)\n",
    "#     # run.config is the input metrics.\n",
    "#     # We remove special values that start with _.\n",
    "    config = {k:v for k,v in run.config.items() if not k.startswith('_')}\n",
    "    config_list.append(config) \n",
    "\n",
    "#     # run.name is the name of the run.\n",
    "    name_list.append(run.name)       \n",
    "\n",
    "import pandas as pd \n",
    "summary_df = pd.DataFrame.from_records(summary_list) \n",
    "config_df = pd.DataFrame.from_records(config_list) \n",
    "name_df = pd.DataFrame({'name': name_list}) \n",
    "all_df = pd.concat([name_df, config_df,summary_df], axis=1)\n",
    "\n",
    "all_df.to_csv(\"./problem1/1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>_wandb</th>\n",
       "      <th>_timestamp</th>\n",
       "      <th>train_acc_step</th>\n",
       "      <th>train_acc_epoch</th>\n",
       "      <th>train_loss_epoch</th>\n",
       "      <th>trainer/global_step</th>\n",
       "      <th>_step</th>\n",
       "      <th>epoch</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>train_loss_step</th>\n",
       "      <th>_runtime</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fix_backbone_0.1</td>\n",
       "      <td>{'runtime': 6665}</td>\n",
       "      <td>1649328205</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.99972</td>\n",
       "      <td>0.001441</td>\n",
       "      <td>156400</td>\n",
       "      <td>3328</td>\n",
       "      <td>200</td>\n",
       "      <td>2.326900</td>\n",
       "      <td>0.586030</td>\n",
       "      <td>6669</td>\n",
       "      <td>0.6254</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fix_backbone_0.0001</td>\n",
       "      <td>{'runtime': 6502}</td>\n",
       "      <td>1649328037</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.99982</td>\n",
       "      <td>0.001364</td>\n",
       "      <td>156400</td>\n",
       "      <td>3328</td>\n",
       "      <td>200</td>\n",
       "      <td>2.292322</td>\n",
       "      <td>0.013677</td>\n",
       "      <td>6501</td>\n",
       "      <td>0.6268</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fix_backbone_0.001</td>\n",
       "      <td>{'runtime': 6642}</td>\n",
       "      <td>1649328179</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.99960</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>156400</td>\n",
       "      <td>3328</td>\n",
       "      <td>200</td>\n",
       "      <td>2.355145</td>\n",
       "      <td>0.079179</td>\n",
       "      <td>6644</td>\n",
       "      <td>0.6203</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All_Layer_ 0.1</td>\n",
       "      <td>{'runtime': 6575}</td>\n",
       "      <td>1649298994</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.99958</td>\n",
       "      <td>0.001589</td>\n",
       "      <td>156400</td>\n",
       "      <td>3328</td>\n",
       "      <td>200</td>\n",
       "      <td>2.319731</td>\n",
       "      <td>0.796069</td>\n",
       "      <td>6574</td>\n",
       "      <td>0.6237</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All_layer_ 0.01</td>\n",
       "      <td>{'runtime': 6574}</td>\n",
       "      <td>1649298993</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.99956</td>\n",
       "      <td>0.001666</td>\n",
       "      <td>156400</td>\n",
       "      <td>3328</td>\n",
       "      <td>200</td>\n",
       "      <td>2.329822</td>\n",
       "      <td>0.880829</td>\n",
       "      <td>6573</td>\n",
       "      <td>0.6225</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>All_Layer_0.0001</td>\n",
       "      <td>{'runtime': 6569}</td>\n",
       "      <td>1649298966</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.99968</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>156400</td>\n",
       "      <td>3328</td>\n",
       "      <td>200</td>\n",
       "      <td>2.334059</td>\n",
       "      <td>0.140334</td>\n",
       "      <td>6567</td>\n",
       "      <td>0.6243</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name             _wandb  _timestamp  train_acc_step  \\\n",
       "0     fix_backbone_0.1  {'runtime': 6665}  1649328205          0.8750   \n",
       "1  fix_backbone_0.0001  {'runtime': 6502}  1649328037          1.0000   \n",
       "2   fix_backbone_0.001  {'runtime': 6642}  1649328179          0.9375   \n",
       "3       All_Layer_ 0.1  {'runtime': 6575}  1649298994          0.7500   \n",
       "4      All_layer_ 0.01  {'runtime': 6574}  1649298993          0.8125   \n",
       "5     All_Layer_0.0001  {'runtime': 6569}  1649298966          1.0000   \n",
       "\n",
       "   train_acc_epoch  train_loss_epoch  trainer/global_step  _step  epoch  \\\n",
       "0          0.99972          0.001441               156400   3328    200   \n",
       "1          0.99982          0.001364               156400   3328    200   \n",
       "2          0.99960          0.001527               156400   3328    200   \n",
       "3          0.99958          0.001589               156400   3328    200   \n",
       "4          0.99956          0.001666               156400   3328    200   \n",
       "5          0.99968          0.001428               156400   3328    200   \n",
       "\n",
       "   test_loss  train_loss_step  _runtime  test_acc      lr  \n",
       "0   2.326900         0.586030      6669    0.6254     0.1  \n",
       "1   2.292322         0.013677      6501    0.6268  0.0001  \n",
       "2   2.355145         0.079179      6644    0.6203   0.001  \n",
       "3   2.319731         0.796069      6574    0.6237     0.1  \n",
       "4   2.329822         0.880829      6573    0.6225    0.01  \n",
       "5   2.334059         0.140334      6567    0.6243  0.0001  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "all_df = pd.read_csv(\"./problem1/1.csv\", index_col=0)\n",
    "all_df[\"lr\"] =  [i.split(\"_\")[-1] for i in all_df[\"name\"]]\n",
    "all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) \n",
    "\n",
    "Next keeping all the hyperparameters same as before (including multi-step learning rate schedule), change the learning rate to 0.01 and 0.1 uniformly for all the layers. This means keep all the layers at same learning rate. So you will be doing two experiments, one keeping learning rate of all layers at 0.01 and one with 0.1. Again finetune the model and report the final accuracy. How does the accuracy with the three learning rates compare ? Which learning rate gives you the best accuracy on the target dataset ? (6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We combine the results of (b) and (c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>epoch</th>\n",
       "      <th>lr</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All_Layer_ 0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All_layer_ 0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>All_Layer_0.0001</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.6243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  epoch      lr  test_acc\n",
       "3    All_Layer_ 0.1    200     0.1    0.6237\n",
       "4   All_layer_ 0.01    200    0.01    0.6225\n",
       "5  All_Layer_0.0001    200  0.0001    0.6243"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cols = [\"test_acc\"]\n",
    "display_cols = [\"name\", \"epoch\", \"lr\"] + accuracy_cols\n",
    "\n",
    "all_df[display_cols][3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best accuracy is obtained with learning rate of 0.0001."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2\n",
    "\n",
    "When using a pretrained model as feature extractor, all the layers of the network are frozen except the final layer. Thus except the last layer, none of the inner layers’ gradients are updated during backward pass with the target dataset. Since gradients do not need to be computed for most of the network, this is faster than finetuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Now train only the last layer for 1, 0.1, 0.01, and 0.001 while keeping all the other hyperparameters and settings same as earlier for finetuning. Which learning rate gives you the best accuracy on the target dataset ? (8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>epoch</th>\n",
       "      <th>lr</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fix_backbone_0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fix_backbone_0.0001</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.6268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fix_backbone_0.001</td>\n",
       "      <td>200</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.6203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name  epoch      lr  test_acc\n",
       "0     fix_backbone_0.1    200     0.1    0.6254\n",
       "1  fix_backbone_0.0001    200  0.0001    0.6268\n",
       "2   fix_backbone_0.001    200   0.001    0.6203"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cols = [\"test_acc\"]\n",
    "display_cols = [\"name\", \"epoch\", \"lr\"] + accuracy_cols\n",
    "\n",
    "all_df[display_cols][0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best accuracy is obtained with learning rate of 0.0001."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) For your target dataset find the best final accuracy (across all the learning rates) from the two transfer learning approaches. Which approach and learning rate is the winner? Provide a plausible explanation to support your observation. (4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not much difference between different learning settings. But the best combination is fix-backbone and only finutune the last layer with learning rate of 0.0001. The reason is that the model will not be overfitting to the target training dataset and can generalize better.\n",
    "\n",
    "Small learning rate is more suitable for the final-layer-tunning."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3f9a4dd55a47a1c8809831ea0aabb012e213f9e932e7e557374d5eaf81edb6c3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
