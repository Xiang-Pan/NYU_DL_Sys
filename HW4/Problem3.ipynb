{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3 - PALEO, FLOPs, Platform Percent of Peak (PPP)\n",
    "This question is based on modeling the execution time of deep learning networks by calculating the floating point operations required at each layer. We looked at two papers in the class, one by Lu et al. and the other by Qi et al."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\n",
    "Why achieving peak FLOPs from hardware devices like GPUs is a difficult propostion in real systems ? How does PPP help in capturing this inefficiency captured in Paleo model. (4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peak FLOPs is a difficult proposition in real systems:\n",
    "- usually requiring customized libraries developed by organizations with intimate knowledge of the underlying hardware\n",
    "- any computation done outside the scope of PALEO (e.g. job scheduling, data copying) will exacerbate the observed inefﬁciency in practice.\n",
    "\n",
    "PPP help in capturing this inefficiency captured in Paleo model:\n",
    "Parameter which captures the average relative inefﬁciency of the platform compared to peak FLOPS. Highly specialized frameworks (e.g. cuDNN) will in general have a computational PPP that is close to 100%, while frameworks with higher overheads may have PPP constants closer to 50% or less.\n",
    "\n",
    "In other works, PPP can help us evaluate how much time the computation is at their peak speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\n",
    "Lu et al. showed that FLOPs consumed by convolution layers in VG16 account for about 99% of the total FLOPS in the forward pass. We will do a similar analysis for VGG19. Calculate FLOPs for different layers in VGG19 and then calculate fraction of the total FLOPs attributed by convolution layers. (6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import vgg16\n",
    "from pthflops import count_ops\n",
    "\n",
    "# Create a network and a corresponding input\n",
    "device = 'cuda:0'\n",
    "model = vgg16().to(device)\n",
    "inp = torch.rand(1,3,224,224).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_list = []\n",
    "for i, x in enumerate(model.features):\n",
    "    name = \"features_\" + str(i)\n",
    "    if not isinstance(x, torch.nn.modules.conv.Conv2d):\n",
    "        ignore_list.append(name)\n",
    "\n",
    "for i, x in enumerate(model.classifier):\n",
    "    name = \"classifier_\" + str(i)\n",
    "    if not isinstance(x, torch.nn.modules.conv.Conv2d):\n",
    "        ignore_list.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['features_1',\n",
       " 'features_3',\n",
       " 'features_4',\n",
       " 'features_6',\n",
       " 'features_8',\n",
       " 'features_9',\n",
       " 'features_11',\n",
       " 'features_13',\n",
       " 'features_15',\n",
       " 'features_16',\n",
       " 'features_18',\n",
       " 'features_20',\n",
       " 'features_22',\n",
       " 'features_23',\n",
       " 'features_25',\n",
       " 'features_27',\n",
       " 'features_29',\n",
       " 'features_30',\n",
       " 'classifier_0',\n",
       " 'classifier_1',\n",
       " 'classifier_2',\n",
       " 'classifier_3',\n",
       " 'classifier_4',\n",
       " 'classifier_5',\n",
       " 'classifier_6']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ignore_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation     OPS          \n",
      "------------  -----------  \n",
      "features_0    89915392     \n",
      "features_2    1852899328   \n",
      "features_5    926449664    \n",
      "features_7    1851293696   \n",
      "features_10   925646848    \n",
      "features_12   1850490880   \n",
      "features_14   1850490880   \n",
      "features_17   925245440    \n",
      "features_19   1850089472   \n",
      "features_21   1850089472   \n",
      "features_24   462522368    \n",
      "features_26   462522368    \n",
      "features_28   462522368    \n",
      "avgpool       1229312      \n",
      "-----------   ----------   \n",
      "Input size: (1, 3, 224, 224)\n",
      "15,361,407,488 FLOPs or approx. 15.36 GFLOPs\n",
      "Operation      OPS          \n",
      "-------------  -----------  \n",
      "features_0     89915392     \n",
      "features_1     6422528      \n",
      "features_2     1852899328   \n",
      "features_3     6422528      \n",
      "features_4     2408448      \n",
      "features_5     926449664    \n",
      "features_6     3211264      \n",
      "features_7     1851293696   \n",
      "features_8     3211264      \n",
      "features_9     1204224      \n",
      "features_10    925646848    \n",
      "features_11    1605632      \n",
      "features_12    1850490880   \n",
      "features_13    1605632      \n",
      "features_14    1850490880   \n",
      "features_15    1605632      \n",
      "features_16    602112       \n",
      "features_17    925245440    \n",
      "features_18    802816       \n",
      "features_19    1850089472   \n",
      "features_20    802816       \n",
      "features_21    1850089472   \n",
      "features_22    802816       \n",
      "features_23    301056       \n",
      "features_24    462522368    \n",
      "features_25    200704       \n",
      "features_26    462522368    \n",
      "features_27    200704       \n",
      "features_28    462522368    \n",
      "features_29    200704       \n",
      "features_30    75264        \n",
      "avgpool        1229312      \n",
      "classifier_0   102764544    \n",
      "classifier_1   8192         \n",
      "classifier_3   16781312     \n",
      "classifier_4   8192         \n",
      "classifier_6   4097000      \n",
      "------------   ----------   \n",
      "Input size: (1, 3, 224, 224)\n",
      "15,516,752,872 FLOPs or approx. 15.52 GFLOPs\n",
      "(15361407488, [['features_0', 89915392], ['features_2', 1852899328], ['features_5', 926449664], ['features_7', 1851293696], ['features_10', 925646848], ['features_12', 1850490880], ['features_14', 1850490880], ['features_17', 925245440], ['features_19', 1850089472], ['features_21', 1850089472], ['features_24', 462522368], ['features_26', 462522368], ['features_28', 462522368], ['avgpool', 1229312]]) (15516752872, [['features_0', 89915392], ['features_1', 6422528], ['features_2', 1852899328], ['features_3', 6422528], ['features_4', 2408448], ['features_5', 926449664], ['features_6', 3211264], ['features_7', 1851293696], ['features_8', 3211264], ['features_9', 1204224], ['features_10', 925646848], ['features_11', 1605632], ['features_12', 1850490880], ['features_13', 1605632], ['features_14', 1850490880], ['features_15', 1605632], ['features_16', 602112], ['features_17', 925245440], ['features_18', 802816], ['features_19', 1850089472], ['features_20', 802816], ['features_21', 1850089472], ['features_22', 802816], ['features_23', 301056], ['features_24', 462522368], ['features_25', 200704], ['features_26', 462522368], ['features_27', 200704], ['features_28', 462522368], ['features_29', 200704], ['features_30', 75264], ['avgpool', 1229312], ['classifier_0', 102764544], ['classifier_1', 8192], ['classifier_3', 16781312], ['classifier_4', 8192], ['classifier_6', 4097000]])\n"
     ]
    }
   ],
   "source": [
    "conv_res = count_ops(model, inp, ignore_layers=ignore_list)\n",
    "total_res = count_ops(model, inp)\n",
    "print(conv_res, total_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of FLOPs attributed by convolution layers in VGG19 is 99.00% for the forward pass.\n"
     ]
    }
   ],
   "source": [
    "ans = \"%.2f\" % (conv_res[0] / total_res[0] * 100)\n",
    "print(f\"The percentage of FLOPs attributed by convolution layers in VGG19 is {ans}% for the forward pass.\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3\n",
    "Study the tables showing timing benchmarks from Alexnet (Table 2), VGG16 (Table 3), Googlenet (Table 5), and Resnet50 (Table 6). Why the measured time and sum of layerwise timings for forward pass did not match on GPUs ? What approach was adopted in Sec. 5 of the paper to mitigate the measurement overhead in GPUs. (2+2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why the measured time and sum of layerwise timings for forward pass did not match on GPUs?**\n",
    "\n",
    "The reason for the mismatch is that CUDA supports asynchronous programming. Before time measurement, an API (cudaDeviceSynchronize) has to be called to make sure that all cores have ﬁnished their tasks. is explicit synchronization is the overhead of measuring time on the GPUs.\n",
    "\n",
    "In other words, when we calculate the layer-wise time, CUDA need addtitionnal call which make the measured time larger than the real case.\n",
    "\n",
    "**What approach was adopted in Sec. 5 of the paper to mitigate the measurement overhead in GPUs?**\n",
    "\n",
    "Transforming the computation into matrix multiplication, which can be accelerately measured by BLAS and cuBLAS libraries. Thus we have a way to accurately approximate and measure the calculation time.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 \n",
    "In Lu et al. FLOPs for different layers of a DNN are calculated. Use FLOPs numbers for VGG16 (Table 3), Googlenet (Table 5), and Resnet50 (Table 6), and calculate the inference time (time to have a forward pass with one image) using published Tflops number for K80 (Refer to NVIDIA TESLA GPU Accelerators) both for single-precision and double-precision calculations. Use this to calculate the peak (theoretical) throughput achieved with K80 for these 3 models. (6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The single-GPU inference time for VGG16 is 0.0017758304696449026s, and the throughput is 563.1168161001096.\n",
      "The double-GPU inference time for VGG16 is 0.005327491408934708s, and the throughput is 187.7056053667032.\n",
      "The single-GPU inference time for GoogLeNet is 0.00018396334478808707s, and the throughput is 5435.865504358655.\n",
      "The double-GPU inference time for GoogLeNet is 0.0005518900343642612s, and the throughput is 1811.9551681195517.\n",
      "The single-GPU inference time for ResNet is 0.0004492554410080183s, and the throughput is 2225.9051504334525.\n",
      "The double-GPU inference time for ResNet is 0.001347766323024055s, and the throughput is 741.9683834778174.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "def get_num(num_str):\n",
    "    res = os.popen(f\"numfmt --from si {num_str}\").read()\n",
    "    res = int(res)\n",
    "    # res = os.system()\n",
    "    return res\n",
    "# print(res)\n",
    "vgg16_total_flops = get_num(\"15503M\")\n",
    "googlenet_total_flops = get_num(\"1606M\")\n",
    "resnet_total_flops = get_num(\"3922M\")\n",
    "\n",
    "\n",
    "k80_single_flops = get_num(\"8.73T\")\n",
    "k80_double_flops = get_num(\"2.91T\")\n",
    "\n",
    "vgg16_single_time = vgg16_total_flops / k80_single_flops\n",
    "vgg16_double_time = vgg16_total_flops / k80_double_flops\n",
    "\n",
    "googlenet_single_time = googlenet_total_flops / k80_single_flops\n",
    "googlenet_double_time = googlenet_total_flops / k80_double_flops\n",
    "\n",
    "resnet_single_time = resnet_total_flops / k80_single_flops\n",
    "resnet_double_time = resnet_total_flops / k80_double_flops\n",
    "\n",
    "\n",
    "vgg16_single_throughput = 1 / vgg16_single_time\n",
    "vgg16_double_throughput = 1 / vgg16_double_time\n",
    "\n",
    "googlenet_single_throughput = 1 / googlenet_single_time\n",
    "googlenet_double_throughput = 1 / googlenet_double_time\n",
    "\n",
    "resnet_single_throughput = 1 / resnet_single_time\n",
    "resnet_double_throughput = 1 / resnet_double_time\n",
    "\n",
    "print(f\"The single-GPU inference time for VGG16 is {vgg16_single_time}s, and the throughput is {vgg16_single_throughput}.\")\n",
    "print(f\"The double-GPU inference time for VGG16 is {vgg16_double_time}s, and the throughput is {vgg16_double_throughput}.\")\n",
    "print(f\"The single-GPU inference time for GoogLeNet is {googlenet_single_time}s, and the throughput is {googlenet_single_throughput}.\")\n",
    "print(f\"The double-GPU inference time for GoogLeNet is {googlenet_double_time}s, and the throughput is {googlenet_double_throughput}.\")\n",
    "print(f\"The single-GPU inference time for ResNet is {resnet_single_time}s, and the throughput is {resnet_single_throughput}.\")\n",
    "print(f\"The double-GPU inference time for ResNet is {resnet_double_time}s, and the throughput is {resnet_double_throughput}.\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3f9a4dd55a47a1c8809831ea0aabb012e213f9e932e7e557374d5eaf81edb6c3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
